{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ci√™ncia dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Pedro Paulo Moreno Camargo\n",
    "\n",
    "Nome: Gabriel Brunoro Tumang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aten√ß√£o: Ser√£o permitidos grupos de tr√™s pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisar√£o fazer um question√°rio de avalia√ß√£o de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Pedro\n",
      "[nltk_data]     Paulo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import emoji\n",
    "nltk.download('stopwords')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diret√≥rio\n",
      "C:\\Users\\Pedro Paulo\\Desktop\\INSPER\\2¬∞ SEMESTRE\\Ci√™ncia dos Dados\\Projeto1CDados\\Projeto_1\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diret√≥rio')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e n√£o relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'La Casa De Papel.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Classifica√ß√£o</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>slc ontem comecei a ver ‚Äúla casa de papel‚Äù man...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mds algu√©m me empresta netflix pra eu ver l√° c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>se bolsonaro fosse um personagem de la casa de...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to vendo l√° casa de papel pela 2 vez ü•∫</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@stefslvatore muri pfvr n me d√° spoiler de la ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  Classifica√ß√£o\n",
       "0  slc ontem comecei a ver ‚Äúla casa de papel‚Äù man...              1\n",
       "1  mds algu√©m me empresta netflix pra eu ver l√° c...              0\n",
       "2  se bolsonaro fosse um personagem de la casa de...              0\n",
       "3             to vendo l√° casa de papel pela 2 vez ü•∫              0\n",
       "4  @stefslvatore muri pfvr n me d√° spoiler de la ...              0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_excel(filename)\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Classifica√ß√£o</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>la casa de papel me decepcionou em um n√≠vel..</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eu assisti la casa de papel de uma vez s√≥ üôÑü§∑üèΩ‚Äç‚ôÄÔ∏è</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@pdrohsou eu vou dar!!!! ontem meu humor n√£o t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eu vou fazer igual o professor em l√° casa de p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>me sentindo uma grandess√≠ssima trouxa por ter ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  Classifica√ß√£o\n",
       "0      la casa de papel me decepcionou em um n√≠vel..              1\n",
       "1   eu assisti la casa de papel de uma vez s√≥ üôÑü§∑üèΩ‚Äç‚ôÄÔ∏è              0\n",
       "2  @pdrohsou eu vou dar!!!! ontem meu humor n√£o t...              1\n",
       "3  eu vou fazer igual o professor em l√° casa de p...              0\n",
       "4  me sentindo uma grandess√≠ssima trouxa por ter ...              1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' professor la casa de papel  '"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Limpeza de Carateres\n",
    "import re      \n",
    "\n",
    "def Remove_URL(dataframe,Index):\n",
    "#Remove Url\n",
    "    dataframe[Index] = dataframe[Index].str.replace('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', ' ')\n",
    "\n",
    "Remove_URL(train, 'Treinamento')\n",
    "\n",
    "Remove_URL(test, 'Teste')\n",
    "\n",
    "#Limpa o Usu√°rio a quem est√° sendo feita a Reply\n",
    "def limpa_username(tweet):\n",
    "    x = re.sub('@[\\w]+ ','',tweet)\n",
    "    return x\n",
    "\n",
    "#Limpa a Hashtag e seu conte√∫do\n",
    "def limpa_hashtag(tweet):\n",
    "    x = re.sub('#[\\w]+ ','',tweet)\n",
    "    return x\n",
    "\n",
    "def cleanup(text):\n",
    "    #import string\n",
    "    limpa_emoji=' '.join(emoji.get_emoji_regexp().split(text))\n",
    "    punctuation = '[!-.:?;/()\\n‚Äú‚Äù]' # Note que os sinais [] s√£o delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, '', limpa_emoji)\n",
    "    return text_subbed\n",
    "\n",
    "\n",
    "\n",
    "#Aplica a exclus√£o das Hashtag, Caracteres e dos Usuarios nos Tweets de Treino\n",
    "lista_sem_reply = []\n",
    "for i in train.Treinamento:\n",
    "    x = limpa_username(i)\n",
    "    z = limpa_hashtag(x)\n",
    "    y = cleanup(z)\n",
    "    lista_sem_reply.append(y)\n",
    "    \n",
    "#Aplica a exclus√£o das Hashtag, Caracteres e dos Usuarios nos Tweets de Teste\n",
    "lista_teste_sem_reply = []\n",
    "for i in test.Teste:\n",
    "    x = limpa_username(i)\n",
    "    z = limpa_hashtag(x)\n",
    "    y = cleanup(z)\n",
    "    lista_teste_sem_reply.append(y)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "train.Treinamento = lista_sem_reply\n",
    "\n",
    "test.Teste = lista_teste_sem_reply\n",
    "\n",
    "valores_teste = lista_teste_sem_reply = []\n",
    "\n",
    "valores = train.Treinamento\n",
    "\n",
    "valores\n",
    "\n",
    "#Tira Stop Words como (artigos, pronomes, preposi√ß√µes ...)\n",
    "\n",
    "\n",
    "\n",
    "Stop_Words = nltk.corpus.stopwords.words('portuguese')\n",
    "\n",
    "def filtro(tweet):\n",
    "    lista_palavras = tweet.split(' ')\n",
    "    string = ''\n",
    "    for palavra in lista_palavras:\n",
    "        if palavra in Stop_Words:\n",
    "            pass\n",
    "        else:\n",
    "            string += palavra + ' '\n",
    "    return string.strip()\n",
    "\n",
    "\n",
    "#Tira Stop Words como (artigos, pronomes, preposi√ß√µes ...) para tweets de Treinamento\n",
    "lista_x = []       \n",
    "for i in valores:\n",
    "    filtrado = filtro(i)\n",
    "    lista_x.append(filtrado)\n",
    "\n",
    "#Tira Stop Words como (artigos, pronomes, preposi√ß√µes ...) para tweets de Teste    \n",
    "lista_y = []\n",
    "for i in valores_teste:\n",
    "    filtrado = filtro(i)\n",
    "    lista_y.append(filtrado)\n",
    "    \n",
    "train.Teste = lista_y\n",
    "\n",
    "teste_filtrado = test\n",
    "    \n",
    "train.Treinamento = lista_x\n",
    "\n",
    "totalmente_filtrado = train\n",
    "\n",
    "test.Teste[8]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separando os Textos de palavras Totais e os de palavras Relevantes  e Irrelevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pega as strings das palavras relevantes e irrelevantes e as armazena\n",
    "contador = 0\n",
    "relevantes = ''\n",
    "irrelevantes = ''\n",
    "for i in train.Classifica√ß√£o:\n",
    "    if i == 1:\n",
    "        relevantes += train.Treinamento[contador] +  ' '\n",
    "    else:\n",
    "        irrelevantes += train.Treinamento[contador]+ ' '\n",
    "    contador += 1\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pega todas as palavras incluindo repetidas que s√£o consideradas relevantes e armazena numa lista\n",
    "todas_palavras_relevantes = relevantes.split()\n",
    "\n",
    "#Cria uma S√©rie desta lista\n",
    "serie_relevantes = pd.Series(todas_palavras_relevantes)\n",
    "\n",
    "#Descobre as frequ√™ncias absolutas das palavras\n",
    "tabela_relevantes = serie_relevantes.value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pega todas as palavras incluindo repetidas que s√£o consideradas irrelevantes e armazena numa lista\n",
    "todas_palavras_irrelevantes = irrelevantes.split()\n",
    "\n",
    "#Cria uma S√©rie desta lista\n",
    "serie_irrelevantes = pd.Series(todas_palavras_irrelevantes)\n",
    "\n",
    "#Descobre as frequ√™ncias absolutas das palavras\n",
    "tabela_irrelevantes = serie_irrelevantes.value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pega todas as palavras n√£o repetidas\n",
    "palavras_totais_nao_repetidas = []\n",
    "\n",
    "for i in serie_relevantes:\n",
    "    if i not in palavras_totais_nao_repetidas:\n",
    "        palavras_totais_nao_repetidas.append(i)\n",
    "        \n",
    "        \n",
    "for i in serie_irrelevantes:\n",
    "    if i not in palavras_totais_nao_repetidas:\n",
    "        palavras_totais_nao_repetidas.append(i)\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pega todas as palavras incluindo repetidas\n",
    "todas_palavras_repetidas = todas_palavras_irrelevantes + todas_palavras_relevantes \n",
    "\n",
    "#Cria uma S√©rie desta lista\n",
    "serie_total = pd.Series(todas_palavras_repetidas)\n",
    "\n",
    "#Descobre as frequ√™ncias absolutas das palavras\n",
    "tabela_total = serie_total.value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cria uma lista em que cada tweet da planilha Teste √© separado por suas respectivas palavras\n",
    "\n",
    "testes = []\n",
    "\n",
    "for i in range(0,len(test.Classifica√ß√£o)):\n",
    "    testes.append(test.Teste[i].split())\n",
    "    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador autom√°tico de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fa√ßa aqui uma descri√ß√£o do seu produto e o que considerou como relevante ou n√£o relevante na classifica√ß√£o dos tweets.\n",
    "\n",
    "O produto escolhido foi a s√©rie da netflix La Casa de Papel que teve sua quinta temporada lan√ßada recentemente. Consideramos como tweets relevantes os tweets que falam sobre a quinta temporada em si, os que as pessoas se emocionaram com a s√©rie e os que falam bem ou mal da s√©rie independentemente de ser uma cr√≠tica construtiva ou n√£o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "#Probabilidades do Tweet ser relevante ou n√£o baseado na planilha Treinamento\n",
    "P_r = len(todas_palavras_relevantes)/len(todas_palavras_repetidas)\n",
    "\n",
    "P_i = len(todas_palavras_irrelevantes)/len(todas_palavras_repetidas)\n",
    "\n",
    "print(P_r + P_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cria uma lista com os valores 0 e 1 para n√£o relevante e relevante respectivamente\n",
    "lista_classificador = []\n",
    "\n",
    "#Fun√ß√£o que descobre a frequ√™ncia absoluta relevante de uma das palavras de um Tweet\n",
    "def ocorrencias_relevantes(palavra):\n",
    "    if palavra not in todas_palavras_relevantes:\n",
    "        freq_absoluta_relevante = 0\n",
    "    else:\n",
    "        freq_absoluta_relevante = tabela_relevantes[palavra]\n",
    "    return freq_absoluta_relevante\n",
    "\n",
    "#Fun√ß√£o que descobre a frequ√™ncia absoluta irrelevante de uma das palavras de um Tweet\n",
    "def ocorrencias_irrelevantes(palavra):\n",
    "    if palavra not in todas_palavras_irrelevantes:\n",
    "        freq_absoluta_irrelevante = 0\n",
    "    else:\n",
    "        freq_absoluta_irrelevante = tabela_irrelevantes[palavra]\n",
    "    return freq_absoluta_irrelevante\n",
    "    \n",
    "for i in range(0,len(testes)):\n",
    "    #√â necess√°rio come√ßar com o valor 1 j√° que o valor 0 multiplicado por qualquer n√∫mero da 0\n",
    "    laplace_relevante = 1\n",
    "    \n",
    "    laplace_irrelevante = 1\n",
    "    \n",
    "    for palavra in testes[i]:\n",
    "        freq_absoluta_relevante = ocorrencias_relevantes(palavra)\n",
    "        \n",
    "        freq_absoluta_irrelevante = ocorrencias_irrelevantes(palavra)\n",
    "        \n",
    "        #Usa a suaviza√ß√£o de Laplace para certa palavra do Tweet e tem seu valor multiplicado pelas suaviza√ß√µes anteriores ou posteriores\n",
    "        laplace_relevante *= (freq_absoluta_relevante + 1)/(len(todas_palavras_relevantes) + len(palavras_totais_nao_repetidas) )\n",
    "        \n",
    "        laplace_irrelevante *= (freq_absoluta_irrelevante + 1)/(len(todas_palavras_irrelevantes) + len(palavras_totais_nao_repetidas))\n",
    "        \n",
    "    #Calculo da Probabilidade do Tweet ser relevante ou n√£o\n",
    "    Prob_tweet_relevante = P_r * laplace_relevante\n",
    "    Prob_tweet_irrelevante = P_i * laplace_irrelevante\n",
    "    \n",
    "    #Classifica os Tweets\n",
    "    if Prob_tweet_relevante > Prob_tweet_irrelevante:\n",
    "        lista_classificador.append(1)\n",
    "        \n",
    "    else:\n",
    "        lista_classificador.append(0)\n",
    "        \n",
    "        \n",
    "\n",
    "#Adiciona mais uma coluna com os valores classificados para o serial test            \n",
    "test['Naive-Bayes'] = lista_classificador     \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora voc√™ deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Classifica√ß√£o</th>\n",
       "      <th>Naive-Bayes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>la casa de papel me decepcionou em um n√≠vel</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eu assisti la casa de papel de uma vez s√≥  üôÑ  ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eu vou dar ontem meu humor n√£o tava dos melhor...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eu vou fazer igual o professor em l√° casa de p...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>me sentindo uma grandess√≠ssima trouxa por ter ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nem falei mas achei essa temporadade la casa d...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>esse final de la casa de papel tnc que odio ü§¨  ü•∫</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>um seriado que todo mundo j√° assistiu mas eu n...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>professor la casa de papel</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>viu a temporada que lan√ßou de la casa de papel...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  Classifica√ß√£o  \\\n",
       "0        la casa de papel me decepcionou em um n√≠vel              1   \n",
       "1  eu assisti la casa de papel de uma vez s√≥  üôÑ  ...              0   \n",
       "2  eu vou dar ontem meu humor n√£o tava dos melhor...              1   \n",
       "3  eu vou fazer igual o professor em l√° casa de p...              0   \n",
       "4  me sentindo uma grandess√≠ssima trouxa por ter ...              1   \n",
       "5  nem falei mas achei essa temporadade la casa d...              1   \n",
       "6  esse final de la casa de papel tnc que odio ü§¨  ü•∫               1   \n",
       "7  um seriado que todo mundo j√° assistiu mas eu n...              0   \n",
       "8                       professor la casa de papel                0   \n",
       "9  viu a temporada que lan√ßou de la casa de papel...              1   \n",
       "\n",
       "   Naive-Bayes  \n",
       "0            1  \n",
       "1            1  \n",
       "2            0  \n",
       "3            0  \n",
       "4            0  \n",
       "5            1  \n",
       "6            1  \n",
       "7            0  \n",
       "8            0  \n",
       "9            1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Naive-Bayes</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classifica√ß√£o</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33.5%</td>\n",
       "      <td>22.5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.0%</td>\n",
       "      <td>31.0%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Naive-Bayes        0      1\n",
       "Classifica√ß√£o              \n",
       "0              33.5%  22.5%\n",
       "1              13.0%  31.0%"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Tabela_Comparativa = pd.crosstab(test.Classifica√ß√£o, test['Naive-Bayes'], normalize = True).mul(100).round(2)\n",
    "display(Tabela_Comparativa.astype(str)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A porcentagem de mensagens relavantes consideradas relevantes foi de 31.0% .\n",
      "A porcentagem de mensagens relavantes consideradas irrelevantes foi de 13.0% .\n",
      "A porcentagem de mensagens irrelavantes consideradas relevantes foi de 22.5% .\n",
      "A porcentagem de mensagens irrelavantes consideradas irrelevantes foi de 33.5% .\n",
      "A acur√°cia do modelo √© de 64.5%\n"
     ]
    }
   ],
   "source": [
    "acuracia = Tabela_Comparativa[0][0] + Tabela_Comparativa[1][1]\n",
    "vn = Tabela_Comparativa[0][0]\n",
    "vp = Tabela_Comparativa[1][1]\n",
    "fp = Tabela_Comparativa[1][0]\n",
    "fn = Tabela_Comparativa[0][1]\n",
    "\n",
    "print('A porcentagem de mensagens relavantes consideradas relevantes foi de {}% .'.format(vp))\n",
    "print('A porcentagem de mensagens relavantes consideradas irrelevantes foi de {}% .'.format(fn))\n",
    "print('A porcentagem de mensagens irrelavantes consideradas relevantes foi de {}% .'.format(fp))\n",
    "print('A porcentagem de mensagens irrelavantes consideradas irrelevantes foi de {}% .'.format(vn))\n",
    "print('A acur√°cia do modelo √© de {}%'.format(acuracia))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Qualidade do Classificador a partir de novas separa√ß√µes dos tweets entre Treinamento e Teste\n",
    "\n",
    "Caso for fazer esse item do Projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfei√ßoamento:\n",
    "\n",
    "Trabalhos que conseguirem pelo menos conceito B v√£o evoluir em conceito dependendo da quantidade de itens avan√ßados:\n",
    "\n",
    "* IMPLEMENTOU outras limpezas e transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o contida nos tweets. Ex: stemming, lemmatization, stopwords\n",
    "* CORRIGIU separa√ß√£o de espa√ßos entre palavras e emojis ou entre emojis e emojis\n",
    "* CRIOU categorias intermedi√°rias de relev√¢ncia baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante. Pelo menos quatro categorias, com adi√ß√£o de mais tweets na base, conforme enunciado. (OBRIGAT√ìRIO PARA TRIOS, sem contar como item avan√ßado)\n",
    "* EXPLICOU porqu√™ n√£o pode usar o pr√≥prio classificador para gerar mais amostras de treinamento\n",
    "* PROP√îS diferentes cen√°rios para Na√Øve Bayes fora do contexto do projeto\n",
    "* SUGERIU e EXPLICOU melhorias reais com indica√ß√µes concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* FEZ o item 6. Qualidade do Classificador a partir de novas separa√ß√µes dos tweets entre Treinamento e Teste descrito no enunciado do projeto (OBRIGAT√ìRIO para conceitos A ou A+)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Refer√™ncias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
