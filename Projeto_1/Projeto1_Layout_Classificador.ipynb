{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ci√™ncia dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Pedro Paulo Moreno Camargo\n",
    "\n",
    "Nome: Gabriel Brunoro Tumang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aten√ß√£o: Ser√£o permitidos grupos de tr√™s pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisar√£o fazer um question√°rio de avalia√ß√£o de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contextualiza√ß√£o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O nosso grupo de Ci√™ncia dos Dados foi contratado pela Netflix para analisar a rea√ß√£o das pessoas em rela√ß√£o a rec√©m lan√ßada 5 temporada da s√©rie mundialmente conhecida \"La Casa de Papel\".\n",
    "\n",
    "Para realizarmos essa an√°lise temos que classificar diferentes Tweets como relevantes ou irrelevantes:\n",
    "\n",
    "Os relevantes seriam Tweets que se encaixam nos t√≥picos abaixo:\n",
    "\n",
    "-Falar bem ou mal da s√©rie sendo eles coment√°rios construtivos ou n√£o.\n",
    "\n",
    "-Falar ou mencionar quinta temporada.\n",
    "\n",
    "-Os Tweets em que mostra que a pessoas se emocionou assistindo a s√©rie.\n",
    "\n",
    "J√° os irrelevantes seriam os Tweets que n√£o abordam nenhum desses t√≥picos.\n",
    "\n",
    "Para realizar a classifica√ß√£o decidimos utilizar o Classificador Naive-Bayes, que √© largamente utilizado em filtros anti-spam de e-mails."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Pedro\n",
      "[nltk_data]     Paulo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import emoji\n",
    "import re     \n",
    "nltk.download('stopwords')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diret√≥rio\n",
      "C:\\Users\\Pedro Paulo\\Desktop\\INSPER\\2¬∞ SEMESTRE\\Ci√™ncia dos Dados\\Projeto1CDados\\Projeto_1\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diret√≥rio')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e n√£o relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'La Casa De Papel.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Classifica√ß√£o</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>slc ontem comecei a ver ‚Äúla casa de papel‚Äù man...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mds algu√©m me empresta netflix pra eu ver l√° c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>se bolsonaro fosse um personagem de la casa de...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to vendo l√° casa de papel pela 2 vez ü•∫</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@stefslvatore muri pfvr n me d√° spoiler de la ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  Classifica√ß√£o\n",
       "0  slc ontem comecei a ver ‚Äúla casa de papel‚Äù man...              1\n",
       "1  mds algu√©m me empresta netflix pra eu ver l√° c...              0\n",
       "2  se bolsonaro fosse um personagem de la casa de...              0\n",
       "3             to vendo l√° casa de papel pela 2 vez ü•∫              0\n",
       "4  @stefslvatore muri pfvr n me d√° spoiler de la ...              0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_excel(filename)\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Classifica√ß√£o</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>la casa de papel me decepcionou em um n√≠vel..</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eu assisti la casa de papel de uma vez s√≥ üôÑü§∑üèΩ‚Äç‚ôÄÔ∏è</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@pdrohsou eu vou dar!!!! ontem meu humor n√£o t...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eu vou fazer igual o professor em l√° casa de p...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>me sentindo uma grandess√≠ssima trouxa por ter ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  Classifica√ß√£o\n",
       "0      la casa de papel me decepcionou em um n√≠vel..            1.0\n",
       "1   eu assisti la casa de papel de uma vez s√≥ üôÑü§∑üèΩ‚Äç‚ôÄÔ∏è            0.0\n",
       "2  @pdrohsou eu vou dar!!!! ontem meu humor n√£o t...            1.0\n",
       "3  eu vou fazer igual o professor em l√° casa de p...            0.0\n",
       "4  me sentindo uma grandess√≠ssima trouxa por ter ...            1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador autom√°tico de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fa√ßa aqui uma descri√ß√£o do seu produto e o que considerou como relevante ou n√£o relevante na classifica√ß√£o dos tweets.\n",
    "\n",
    "O produto escolhido foi a s√©rie da netflix La Casa de Papel que teve sua quinta temporada lan√ßada recentemente. Consideramos como tweets relevantes os tweets que falam ou mencionam sobre a quinta temporada em si, os que as pessoas se emocionaram com a s√©rie e os que falam bem ou mal da s√©rie independentemente de ser uma cr√≠tica construtiva ou n√£o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpeza de Caraceteres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fun√ß√£o para Remover Sites dos Tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Limpeza de Carateres \n",
    "\n",
    "def Remove_URL(dataframe,Index):\n",
    "#Remove Url\n",
    "    dataframe[Index] = dataframe[Index].str.replace('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', ' ')\n",
    "\n",
    "Remove_URL(train, 'Treinamento')\n",
    "\n",
    "Remove_URL(test, 'Teste')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fun√ß√£o para remover os usu√°rios de um Tweet. Ex: @joao_123\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Limpa o Usu√°rio a quem est√° sendo feita a Reply\n",
    "def limpa_username(tweet):\n",
    "    x = re.sub('@[\\w]+ ','',tweet)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fun√ß√£o para separar emojis entre si e as palavra e limpar pontua√ß√µes consideradas desnecess√°rias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup(text):\n",
    "    #import string\n",
    "    limpa_emoji=' '.join(emoji.get_emoji_regexp().split(text))\n",
    "    punctuation = '[!-.:?;/()\\n‚Äú‚Äù]' # Note que os sinais [] s√£o delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, '', limpa_emoji)\n",
    "    return text_subbed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplica√ß√£o dessas Fun√ß√µes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aplica a exclus√£o das Hashtag, Caracteres e dos Usuarios nos Tweets de Treino\n",
    "lista_sem_reply = []\n",
    "for i in train.Treinamento:\n",
    "    x = limpa_username(i)\n",
    "    y = cleanup(x)\n",
    "    lista_sem_reply.append(y)\n",
    "    \n",
    "#Aplica a exclus√£o das Hashtag, Caracteres e dos Usuarios nos Tweets de Teste\n",
    "lista_teste_sem_reply = []\n",
    "for i in test.Teste:\n",
    "    x = limpa_username(i)\n",
    "    y = cleanup(x)\n",
    "    lista_teste_sem_reply.append(y)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "train.Treinamento = lista_sem_reply\n",
    "\n",
    "test.Teste = lista_teste_sem_reply\n",
    "\n",
    "valores_teste = lista_teste_sem_reply = []\n",
    "\n",
    "valores = train.Treinamento\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove Palavras como artigos pronomes e preposi√ß√µes. Exemplos: Eu, ele, uns, umas..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tira Stop Words como (artigos, pronomes, preposi√ß√µes ...)\n",
    "\n",
    "\n",
    "\n",
    "Stop_Words = nltk.corpus.stopwords.words('portuguese')\n",
    "\n",
    "def filtro(tweet):\n",
    "    lista_palavras = tweet.split(' ')\n",
    "    string = ''\n",
    "    for palavra in lista_palavras:\n",
    "        if palavra in Stop_Words:\n",
    "            pass\n",
    "        else:\n",
    "            string += palavra + ' '\n",
    "    return string.strip()\n",
    "\n",
    "\n",
    "#Tira Stop Words como (artigos, pronomes, preposi√ß√µes ...) para tweets de Treinamento\n",
    "lista_x = []       \n",
    "for i in valores:\n",
    "    filtrado = filtro(i)\n",
    "    lista_x.append(filtrado)\n",
    "\n",
    "#Tira Stop Words como (artigos, pronomes, preposi√ß√µes ...) para tweets de Teste    \n",
    "lista_y = []\n",
    "for i in valores_teste:\n",
    "    filtrado = filtro(i)\n",
    "    lista_y.append(filtrado)\n",
    "    \n",
    "\n",
    "teste_filtrado = test\n",
    "    \n",
    "train.Treinamento = lista_x\n",
    "\n",
    "totalmente_filtrado = train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separa√ß√£o dos Tweets: Relevantes, N√£o Relevantes e Total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Armazena todas as palavras relevantes e irrelevantes separadamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pega as strings das palavras relevantes e irrelevantes e as armazena\n",
    "contador = 0\n",
    "relevantes = ''\n",
    "irrelevantes = ''\n",
    "for i in train.Classifica√ß√£o:\n",
    "    if i == 1:\n",
    "        relevantes += train.Treinamento[contador] +  ' '\n",
    "    else:\n",
    "        irrelevantes += train.Treinamento[contador]+ ' '\n",
    "    contador += 1\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guarda em uma base de dados(pd.Series) todas as palavras relevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pega todas as palavras incluindo repetidas que s√£o consideradas relevantes e armazena numa lista\n",
    "todas_palavras_relevantes = relevantes.split()\n",
    "\n",
    "#Cria uma S√©rie desta lista\n",
    "serie_relevantes = pd.Series(todas_palavras_relevantes)\n",
    "\n",
    "#Descobre as frequ√™ncias absolutas das palavras\n",
    "tabela_relevantes = serie_relevantes.value_counts()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guarda em uma base de dados(pd.Series) todas as palavras irrelevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pega todas as palavras incluindo repetidas que s√£o consideradas irrelevantes e armazena numa lista\n",
    "todas_palavras_irrelevantes = irrelevantes.split()\n",
    "\n",
    "#Cria uma S√©rie desta lista\n",
    "serie_irrelevantes = pd.Series(todas_palavras_irrelevantes)\n",
    "\n",
    "#Descobre as frequ√™ncias absolutas das palavras\n",
    "tabela_irrelevantes = serie_irrelevantes.value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guarda em uma lista todas as palavras relevantes e irrelevantes n√£o repetidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pega todas as palavras n√£o repetidas\n",
    "palavras_totais_nao_repetidas = []\n",
    "\n",
    "for i in serie_relevantes:\n",
    "    if i not in palavras_totais_nao_repetidas:\n",
    "        palavras_totais_nao_repetidas.append(i)\n",
    "        \n",
    "        \n",
    "for i in serie_irrelevantes:\n",
    "    if i not in palavras_totais_nao_repetidas:\n",
    "        palavras_totais_nao_repetidas.append(i)\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guarda em uma base de dados(pd.Series) todas as palavras incluindo repeti√ß√µes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pega todas as palavras incluindo repetidas\n",
    "todas_palavras_repetidas = todas_palavras_irrelevantes + todas_palavras_relevantes \n",
    "\n",
    "#Cria uma S√©rie desta lista\n",
    "serie_total = pd.Series(todas_palavras_repetidas)\n",
    "\n",
    "#Descobre as frequ√™ncias absolutas das palavras\n",
    "tabela_total = serie_total.value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cria uma matriz em que cada Tweet presente na lista possui dentro de si uma lista de palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cria uma lista em que cada tweet da planilha Teste √© separado por suas respectivas palavras\n",
    "\n",
    "testes = []\n",
    "\n",
    "for i in range(0,len(test.Classifica√ß√£o)):\n",
    "    testes.append(test.Teste[i].split())\n",
    "    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probabilidades Iniciais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiramente √© necess√°rio descobrir a probabilidade de palavras relevantes ou irrelevantes dado as palavras totais.\n",
    "\n",
    "-NI( N√∫mero de palavras Irrelevantes)\n",
    "\n",
    "-NR (N√∫mero de palavras Relevantes)\n",
    "\n",
    "-Total\n",
    "\n",
    "\n",
    "$\\quad P(R) = \\frac{NR}{Total}$\n",
    "\n",
    "$\\quad P(I)= \\frac{NI}{Total}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "#Probabilidades do Tweet ser relevante ou n√£o baseado na planilha Treinamento\n",
    "P_r = len(todas_palavras_relevantes)/len(todas_palavras_repetidas)\n",
    "\n",
    "P_i = len(todas_palavras_irrelevantes)/len(todas_palavras_repetidas)\n",
    "\n",
    "print(P_r + P_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive-Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "√â poss√≠vel utilizar o **Teorema de Bayes** para obter uma probabilidade condicional $P(R|Tweet)$ da seguinta forma:\n",
    "\n",
    "$$P(R|Tweet) = \\frac{P(Tweet|R) P(R)}{P(Tweet)}$$\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "O processo √© an√°logo para $P(I|Tweet)$:\n",
    "\n",
    "$$P(I|Tweet) = \\frac{P(Tweet|I) P(I)}{P(Tweet)}$$\n",
    "\n",
    "Probabilidades necess√°rias para realizar o calculo: \n",
    "- $P(R|Tweet)$\n",
    "- $P(I|Tweet)$\n",
    "- $P(R)$:\n",
    "- $P(I)$\n",
    "- $P(Tweet)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A ingenuidade - Na√Øve Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A parte ing√™nua do Na√Øve Bayes, que consiste em assumir que as palavras s√£o independentes entre si e que sua ordem na frase n√£o importa. \n",
    "\n",
    "\n",
    "Ou seja:\n",
    "\n",
    "p = primeira palavra\n",
    "\n",
    "p2 = segunda palavra\n",
    "\n",
    "pn = n-√©sima palavra \n",
    "\n",
    "$\\quad P(R|Tweet) = \n",
    "\\frac{P(p|R)\\cdot P(p2|R)\\cdot P(p3|R)\\cdot ... P(pn|R)\\cdot P(R)\\cdot}{P(Tweet)}$\n",
    "\n",
    "$\\quad P(I|Tweet) = \n",
    "\\frac{P(p|I)\\cdot P(p2|I)\\cdot P(p3|I)\\cdot ... P(pn|I)\\cdot P(I)\\cdot}{P(Tweet)}$\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mas e se a palavra n n√£o existir em R ou I?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P(pn|I) = 0$\n",
    "\n",
    "$P(pn|R) = 0$\n",
    "\n",
    "usando a formula acima:\n",
    "\n",
    "$P(R|Tweet) = 0$\n",
    "\n",
    "$P(I|Tweet) = 0$\n",
    "\n",
    "Isso √© incab√≠vel, como resolver?\n",
    "\n",
    "Uma maneira √© o m√©todo de Suaviza√ß√£o de Laplace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Suaviza√ß√£o de Laplace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vari√°veis:\n",
    "\n",
    "Far = Frequ√™ncia absoluta relevante da palavra\n",
    "\n",
    "Prr =Frequ√™ncia absoluta da palavra no conjunto de palavras relevantes \n",
    "\n",
    "Ptnr = Frequ√™ncia absoluta do total de palavras n√£o incuindo palavras repetidas\n",
    "\n",
    "Fir = Frequ√™ncia absoluta da palavra no conjunto de palavras irrelevantes \n",
    "\n",
    "Pir = Frequ√™ncia absoluta de palavras irrelevantes incluindo repetidas\n",
    "\n",
    "\n",
    "\n",
    "$ P(pn|R) = \\frac{Far + 1}{Prr + Ptnr}$\n",
    "\n",
    "$ P(pn|I) = \\frac{Fai + 1}{Pir + Ptnr}$\n",
    "\n",
    "Desse modo:\n",
    "\n",
    "Caso n√£o haja a palavra na base de dados R ou I:\n",
    "\n",
    "$ P(pn|R) = \\frac{0 + 1}{Prr + Ptnr}$\n",
    "\n",
    "$ P(pn|I) = \\frac{0 + 1}{Pir + Ptnr}$\n",
    "\n",
    "Desse modo $ P(pn|R)$ e $ P(pn|I)$ s√£o diferentes de 0, impedindo o que aconteceu anteriormente.\n",
    "\n",
    "J√° que os dois est√£o sendo divididos por $P(Tweet)$ √© poss√≠vel cortar essa probabilidade.\n",
    "\n",
    "Aplicando a formula abaixo a partir de laplace:\n",
    "\n",
    "$\\quad P(R|Tweet) = P(p|R)\\cdot P(p2|R)\\cdot P(p3|R)\\cdot ... P(pn|R)\\cdot P(R)$\n",
    "\n",
    "$\\quad P(I|Tweet) = P(p|I)\\cdot P(p2|I)\\cdot P(p3|I)\\cdot ... P(pn|I)\\cdot P(I)$\n",
    "\n",
    "\n",
    "Assim, a **Classifica√ß√£o da frase** se dar√° conforme abaixo:\n",
    "\n",
    "$\\quad \\Rightarrow$ Se $P(R|Tweet) > P(I|Tweet)$, ent√£o o Tweet ser√° classificado como de *Relevante*\n",
    "\n",
    "$\\quad \\Rightarrow$ Se $P(R|Tweet) < P(I|Tweet)$, ent√£o o Tweet ser√° classificado como de *Irrelevante*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Colocando isto em pr√°tica:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cria uma lista com os valores 0 e 1 para n√£o relevante e relevante respectivamente\n",
    "lista_classificador = []\n",
    "\n",
    "#Fun√ß√£o que descobre a frequ√™ncia absoluta relevante de uma das palavras de um Tweet\n",
    "def ocorrencias_relevantes(palavra):\n",
    "    if palavra not in todas_palavras_relevantes:\n",
    "        freq_absoluta_relevante = 0\n",
    "    else:\n",
    "        freq_absoluta_relevante = tabela_relevantes[palavra]\n",
    "    return freq_absoluta_relevante\n",
    "\n",
    "#Fun√ß√£o que descobre a frequ√™ncia absoluta irrelevante de uma das palavras de um Tweet\n",
    "def ocorrencias_irrelevantes(palavra):\n",
    "    if palavra not in todas_palavras_irrelevantes:\n",
    "        freq_absoluta_irrelevante = 0\n",
    "    else:\n",
    "        freq_absoluta_irrelevante = tabela_irrelevantes[palavra]\n",
    "    return freq_absoluta_irrelevante\n",
    "    \n",
    "for i in range(0,len(testes)):\n",
    "    #√â necess√°rio come√ßar com o valor 1 j√° que o valor 0 multiplicado por qualquer n√∫mero da 0\n",
    "    laplace_relevante = 1\n",
    "    \n",
    "    laplace_irrelevante = 1\n",
    "    \n",
    "    for palavra in testes[i]:\n",
    "        freq_absoluta_relevante = ocorrencias_relevantes(palavra)\n",
    "        \n",
    "        freq_absoluta_irrelevante = ocorrencias_irrelevantes(palavra)\n",
    "        \n",
    "        #Usa a suaviza√ß√£o de Laplace para certa palavra do Tweet e tem seu valor multiplicado pelas suaviza√ß√µes anteriores ou posteriores\n",
    "        laplace_relevante *= (freq_absoluta_relevante + 1)/(len(todas_palavras_relevantes) + len(palavras_totais_nao_repetidas) )\n",
    "        \n",
    "        laplace_irrelevante *= (freq_absoluta_irrelevante + 1)/(len(todas_palavras_irrelevantes) + len(palavras_totais_nao_repetidas))\n",
    "        \n",
    "    #Calculo da Probabilidade do Tweet ser relevante ou n√£o\n",
    "    Prob_tweet_relevante = P_r * laplace_relevante\n",
    "    Prob_tweet_irrelevante = P_i * laplace_irrelevante\n",
    "    \n",
    "    #Classifica os Tweets\n",
    "    if Prob_tweet_relevante > Prob_tweet_irrelevante:\n",
    "        lista_classificador.append(1)\n",
    "        \n",
    "    else:\n",
    "        lista_classificador.append(0)\n",
    "        \n",
    "        \n",
    "\n",
    "#Adiciona mais uma coluna com os valores classificados para o serial test            \n",
    "test['Naive-Bayes'] = lista_classificador     \n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora voc√™ deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Classifica√ß√£o</th>\n",
       "      <th>Naive-Bayes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>la casa de papel me decepcionou em um n√≠vel</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eu assisti la casa de papel de uma vez s√≥  üôÑ  ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eu vou dar ontem meu humor n√£o tava dos melhor...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eu vou fazer igual o professor em l√° casa de p...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>me sentindo uma grandess√≠ssima trouxa por ter ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nem falei mas achei essa temporadade la casa d...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>esse final de la casa de papel tnc que odio ü§¨  ü•∫</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>um seriado que todo mundo j√° assistiu mas eu n...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>professor la casa de papel</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>viu a temporada que lan√ßou de la casa de papel...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  Classifica√ß√£o  \\\n",
       "0        la casa de papel me decepcionou em um n√≠vel            1.0   \n",
       "1  eu assisti la casa de papel de uma vez s√≥  üôÑ  ...            0.0   \n",
       "2  eu vou dar ontem meu humor n√£o tava dos melhor...            1.0   \n",
       "3  eu vou fazer igual o professor em l√° casa de p...            0.0   \n",
       "4  me sentindo uma grandess√≠ssima trouxa por ter ...            1.0   \n",
       "5  nem falei mas achei essa temporadade la casa d...            1.0   \n",
       "6  esse final de la casa de papel tnc que odio ü§¨  ü•∫             1.0   \n",
       "7  um seriado que todo mundo j√° assistiu mas eu n...            0.0   \n",
       "8                       professor la casa de papel              0.0   \n",
       "9  viu a temporada que lan√ßou de la casa de papel...            1.0   \n",
       "\n",
       "   Naive-Bayes  \n",
       "0            1  \n",
       "1            1  \n",
       "2            0  \n",
       "3            0  \n",
       "4            0  \n",
       "5            1  \n",
       "6            1  \n",
       "7            0  \n",
       "8            0  \n",
       "9            1  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compara√ß√£o do Classificador x Base de Testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Naive-Bayes</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classifica√ß√£o</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>35.0%</td>\n",
       "      <td>20.5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>13.5%</td>\n",
       "      <td>31.0%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Naive-Bayes        0      1\n",
       "Classifica√ß√£o              \n",
       "0.0            35.0%  20.5%\n",
       "1.0            13.5%  31.0%"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Tabela_Comparativa = pd.crosstab(test.Classifica√ß√£o, test['Naive-Bayes'], normalize = True).mul(100).round(4)\n",
    "display(Tabela_Comparativa.astype(str)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calcula  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A porcentagem de mensagens relavantes consideradas relevantes foi de 31.0% .\n",
      "A porcentagem de mensagens relavantes consideradas irrelevantes foi de 13.5% .\n",
      "A porcentagem de mensagens irrelavantes consideradas relevantes foi de 20.5% .\n",
      "A porcentagem de mensagens irrelavantes consideradas irrelevantes foi de 35.0% .\n",
      "A acur√°cia do modelo √© de 66.0%\n"
     ]
    }
   ],
   "source": [
    "acuracia = Tabela_Comparativa[0][0] + Tabela_Comparativa[1][1]\n",
    "vn = Tabela_Comparativa[0][0]\n",
    "vp = Tabela_Comparativa[1][1]\n",
    "fp = Tabela_Comparativa[1][0]\n",
    "fn = Tabela_Comparativa[0][1]\n",
    "\n",
    "print('A porcentagem de mensagens relavantes consideradas relevantes foi de {}% .'.format(vp))\n",
    "print('A porcentagem de mensagens relavantes consideradas irrelevantes foi de {}% .'.format(fn))\n",
    "print('A porcentagem de mensagens irrelavantes consideradas relevantes foi de {}% .'.format(fp))\n",
    "print('A porcentagem de mensagens irrelavantes consideradas irrelevantes foi de {}% .'.format(vn))\n",
    "print('A acur√°cia do modelo √© de {}%'.format(acuracia))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em suma, nosso classificador teve uma performance razo√°vel, j√° que possui uma acur√°cia de 66.0%, sendo assim 66.0% das mensagens foram classificadas como deveriam.\n",
    "\n",
    "Entre as mensagens, elas foram classificadas de 4 maneiras diferentes:\n",
    "\n",
    "-As verdadeiras positivas que constituem 31,0%, sendo elas mensagens relevantes classificadas como relevantes.\n",
    "\n",
    "-As verdadeiras negativas que constituem 35,0%, sendo elas mensagens irrelevantes e que s√£o\n",
    "classificadas como irrelevantes.\n",
    "\n",
    "-As falso positivos que constituem 20,5%, sendo elas mensagens irrelevantes e que s√£o classificadas\n",
    "como relevantes.\n",
    "\n",
    "-As falsos negativos que constituem 13,5% das mensagens, sendo elas mensagens relevantes e que s√£o classificadas\n",
    "como irrelevantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A maior quantidade de erros do nosso classificador s√£o dados por falsos positivos, a performance do nosso modelo pode ter sido afetada por diferentes raz√µes:\n",
    "\n",
    "-Uma dessas raz√µes √© o fato que o classificador √© dependente da base de dados usada no treinamento, sendo assim a chance dele classificar err√¥neamente uma frase aumenta caso v√°rias palavras dessa frase n√£o estejam nessa base de dados. Isso o torna enviesado a partir de sua base de dados usada em seu treinamento.\n",
    "\n",
    "-Outra delas √© dada por o classificador calcular a possibilidade de uma mensagem ser relevante ou n√£o por um modelo inteiramente matem√°tico, sem levar em conta o sentido sem√¢ntico de palavras e g√≠rias da l√≠ngua portuguesa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como dito antes no nosso projeto os Tweets foram classificados como relevante caso eles fizessem parte de um desses t√≥picos:\n",
    "\n",
    "-Falar bem ou mal da s√©rie sendo eles coment√°rios construtivos ou n√£o.\n",
    "\n",
    "-Falar ou mencionar quinta temporada.\n",
    "\n",
    "-Os Tweets em que mostra que a pessoas se emocionou assistindo a s√©rie.\n",
    "\n",
    "Sendo assim, as frases de sarcasmo e dupla nega√ß√£o podem ser consideradas irrelevantes quando o t√≥pico √© falar positivamente ou negativamente da s√©rie. Um exemplo que n√£o est√° na base de treinamento ou de testes √© a frase \"Eu amo a s√©rie #sqn\" ou a frase \"Eu n√£o vi ningu√©m que realmente gosta s√©rie\", nessas frases o sentido sem√¢ntico n√£o importa j√° que mesmo que o classificador veja essa frase como um coment√°rio que fala bem ou mal da s√©rie a √∫nica coisa que importa √© so classificador conseguir√° classificar essa mensagem como relevante ou n√£o.\n",
    "\n",
    "Ocorre uma coisa parecida para o t√≥pico de falar sobre a quinta temporada, j√° que nele as frases de sarcasmo e dupla nega√ß√£o podem ser consideradas irrelevantes, uma vez que caso ele mencione a quinta temporada n√£o importa se a frase possui sarcasmo ou dupla nega√ß√£o.\n",
    "\n",
    "J√° no t√≥pico da pessoas terem se emocionado assistindo a s√©rie as frases de sarcasmo e dupla nega√ß√£o podem impactar a classifica√ß√£o. Para ver isso em pr√°tica foi adicionado um Tweet sarc√°stico pela nossa equipe na posi√ß√£o 200 da base de dados(esse Tweet por n√£o ter sido classifica√ß√£o manualmente n√£o impacta a acur√°cia do classificador calculada pr√©viamente) , nele o Tweet que era pra ser classificado como irrelevante foi classificado como relevante, dessa maneira √© poss√≠vel enxergar como nosso modelo matem√°tico √© ingenuo nesse t√≥pico j√° pode acabar se confundindo em rela√ß√£o a frases sarc√°sticas e de dupla nega√ß√£o."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nossa equipe possui um plano de expans√£o em mente para o futuro, ele consiste em:\n",
    "\n",
    "-Lematizar as palavras da base de dados a fim de aumentar ainda mais a acur√°cia, j√° que palavras diferentes como jogam e jogar seriam consideradas uma √∫nica palavra ap√≥s a lematiza√ß√£o.\n",
    "\n",
    "-Comparar diferentes resultados da classifica√ß√£o baseados em diferentes dados usados pra o treino a fim de diminuir o vi√©s do classificador.\n",
    "\n",
    "-Criar um classificador diferente para cada t√≥pico facilitando a busca por dados espec√≠ficos pela empresa.\n",
    "\n",
    "\n",
    "Dado a proposta de expans√£o acima acredito que esse projeto deve continuar com o seu financiamento.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Qualidade do Classificador a partir de novas separa√ß√µes dos tweets entre Treinamento e Teste\n",
    "\n",
    "Caso for fazer esse item do Projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfei√ßoamento:\n",
    "\n",
    "Trabalhos que conseguirem pelo menos conceito B v√£o evoluir em conceito dependendo da quantidade de itens avan√ßados:\n",
    "\n",
    "* IMPLEMENTOU outras limpezas e transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o contida nos tweets. Ex: stemming, lemmatization, stopwords\n",
    "* CORRIGIU separa√ß√£o de espa√ßos entre palavras e emojis ou entre emojis e emojis\n",
    "* CRIOU categorias intermedi√°rias de relev√¢ncia baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante. Pelo menos quatro categorias, com adi√ß√£o de mais tweets na base, conforme enunciado. (OBRIGAT√ìRIO PARA TRIOS, sem contar como item avan√ßado)\n",
    "* EXPLICOU porqu√™ n√£o pode usar o pr√≥prio classificador para gerar mais amostras de treinamento\n",
    "* PROP√îS diferentes cen√°rios para Na√Øve Bayes fora do contexto do projeto\n",
    "* SUGERIU e EXPLICOU melhorias reais com indica√ß√µes concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* FEZ o item 6. Qualidade do Classificador a partir de novas separa√ß√µes dos tweets entre Treinamento e Teste descrito no enunciado do projeto (OBRIGAT√ìRIO para conceitos A ou A+)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Refer√™ncias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
